{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 신경망의 톱니바퀴 : 텐서 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 원소별 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원소별 연산  \n",
    "- relu 함수와 덧셈  \n",
    "- 텐서에 있는 각 원소에 독립적으로 적용(고도의 병렬 구현이 가능한 연산)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. relu 함수\n",
    "def navice_relu(x):\n",
    "    assert len(x.shape)==2 # assert는 뒤의 조건이 true가 아니면 AssertError 발생\n",
    "                            # x는 2D 넘파이 배열\n",
    "    \n",
    "    x = x.cope() # 입력 텐서 자체를 바꾸지 않도록 복사*\n",
    "    for i in range(x.shape[0]): # shape : 차원\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] = max(x[i,j],0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- assert 함수 (참고:https://wikidocs.net/21050)  \n",
    "- 파이썬의 함수 매개변수는 수정 가능한 데이터 타입(리스트, 딕셔너리 등)일 경우 참조에 의한 호출처럼 작동하기 때문에 입력 배열 원본을 변경시키지 않기 위해 복사하여 사용*  \n",
    "(참고1 : https://wikidocs.net/16038)  \n",
    "(참고2 : https://blueshw.github.io/2016/01/20/shallow-copy-deep-copy/)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# shape 함수\n",
    "import numpy as np\n",
    "a = np.array([[0, 1, 2], [3, 4, 5]])    # 2 x 3의 NumPy 2차원 배열 생성\n",
    "print(np.shape(a))\n",
    "print(np.shape(a)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 덧셈\n",
    "def navie_add(X,y):\n",
    "    assert len(x.shape) == 2 # x와 y는 2D 넘파이 배열\n",
    "    assert x.shape == y.shape\n",
    "    \n",
    "    x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] += y[i,j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# 3. 넘파이 배열을 다룰 때 최적화된 넘파이 내장 함수 사용\n",
    "x=1;y=2\n",
    "\n",
    "import numpy as np\n",
    "z= x+y # 원소별 덧셈\n",
    "x = np.maximum(z,0.) # 원소별 렐루 함수\n",
    "\n",
    "print(z)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- relu(x) = max(x,0)\n",
    "- 렐루(Relu) 함수는 입력이 0보다 크면 입력을 그대로 반환하고 0보다 작으면 0을 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 브로드캐스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 브로드캐스팅?  \n",
    "크기가 다르 두 텐서가 더해질 때 작은 텐서가 큰 텐서의 크기에 만춰 브로드캐스팅이 된다. \n",
    "\n",
    "\n",
    "2. 브로드캐스팅의 단계  \n",
    "(1) 큰 텐서의 ndim에 맞도록 작은 텐서에 (브로드캐스팅 축이라고 부르는) 축이 추가된다.  \n",
    "(2) 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복된다.  \n",
    "\n",
    "ex. x의 크기 : (32,10), y의 크기 : (10,)  \n",
    "(1) y에 비어 있는 첫 번째 축을 추가하여 크기를 (1,10)으로 만든다.  \n",
    "(2) y를 이 축에 32번 반복하면 텐서 Y의 크기는 (32,10)이 된다.  \n",
    "(Y{i,:] == y for i in range(0,32))  \n",
    "(3) x와 y의 크기가 같기 때문에 더할 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x,y):\n",
    "    assert len(x.shape) == 2 # x는 2D 넘파이 배열\n",
    "    assert len(y,shape) == 1 # y는 넘파이 벡터\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] += y[j]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (a, b, ... n, n+1, ... m) 크기의 텐서와 (n, n+1, ... m) 크기의 텐서 사이에 브로드캐스팅으로 원소별 연산을 적용할 수 있다.  \n",
    "- 이 때 브로드캐스팅은 a부터 n-1까지의 축에 자동으로 일어난다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크기가 다른 두 텐서에 브로드캐스팅으로 원소별 maximum 연산을 적용한 예\n",
    "import numpy as np\n",
    "x = np.random.random((64,3,32,10)) # x는 (64,3,32,10) 크기의 랜덤 텐서\n",
    "y = np.random.random((32,10))  # y는 (32,10) 크기의 랜덤 텐서\n",
    "z = np.maximum(x,y) # 출력 z 크기는 x와 동일하게 (64,3,32,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- random.random() : 난수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 텐서 점곱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서 점곱(= 텐서 곱셈(tensor product))\n",
    "- 가장 널리 사용되고 유용한 텐서 연산  \n",
    "- 원소별 곱셈과 다르다.  \n",
    "- 원소별 연산과 반대로 입력 텐서의 원소들을 결합시킨다.  \n",
    "\n",
    "\n",
    "- 넘파이, 케라스, 씨아노, 텐서플로에서 원소별 곱셈 : * 연산자\n",
    "- 텐서플로에서는 dot 연산자가 다르지만 넘파이, 케라스에서 점곱 연산에 dot 연산자를 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (64,3,32,10) and (32,10) not aligned: 10 (dim 3) != 32 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-deb721d55b13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (64,3,32,10) and (32,10) not aligned: 10 (dim 3) != 32 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "z = np.dot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dot 연산  \n",
    "참고 : http://blog.naver.com/PostView.nhn?blogId=cjh226&logNo=221356199190&redirect=Dlog&widgetTypeCall=true&directAccess=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 2개의 벡터 x와 y의 점곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x,y):\n",
    "    assert len(x.shape)==1\n",
    "    assert len(y.shape)==1 # x와 y는 넘파이 벡터\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    \n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 벡터의 점곱은 스칼라가 되기 때문에 원소 개수가 같은 벡터끼리 점곱이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 행렬 x와 벡터 y의 점곱\n",
    "- y와 x의 행 사이에서 점곱이 일어나기 때문에 벡터가 반환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def navie_matrix_vector_dot(x,y):\n",
    "    assert len(x.shape) == 2 # x는 넘파이 행렬\n",
    "    assert len(y.shape) == 1 # y는 넘파이 벡터\n",
    "    assert x.shape[1] == y.shape[0] # x의 두 번째 차원이 y의 첫번째 차원과 같아야 한다.\n",
    "    \n",
    "    z = np.zeros(x.shape[0]) # x의 행과 같은 크기의 0이 채워진 벡터를 만든다.\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i,j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- array 생성 함수 중 zeros  \n",
    "(참고 : https://firework-ham.tistory.com/33)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navie_matrix_vector_dot(x,y):\n",
    "    z = np.zeros(x.shapes[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i,:],y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬-벡터 점곱과 벡터- 벡터 점곱 사이의 관계를 부각하기 위해 앞에서 만든 함수를 재사용  \n",
    "- 두 텐서 중 하나라도 ndim이 1보다 크면 dot 연산에 교환 법칙이 성립되지 않는다.  \n",
    "=> dot(x,y)와 dot(y,x)가 같지 않다.  \n",
    "(벡터-벡터 점곱은 교환 법칙 성립, 행렬-벡터, 행렬-행렬 점곱은 교환법칙 성립 X)  \n",
    "\n",
    "\n",
    "- 물론 점곱은 임의의 축 개수를 가진 텐서에 일반화된다. 가장 일반적인 용도는 두 행렬 간의 점곱일 것이다. x.shape[1] == y.shape[0]일 때 두 행렬 x와 y의 점곱(dot(x,y))이 성립된다. x의 열과 y의 행 사이 벡터 점곱으로 인해 (x.shape[0], y.shape[1]) 크기의 행렬이 된다. 다음은 단순한 구현 예이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 행렬 x와 행렬 y의 점곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x,y):\n",
    "    assert len(x.shape)==2\n",
    "    assert len(y.shape)==2 # x와 y는 넘파이 행렬이다.\n",
    "    assert x.shape[1] == y.shape[0] # x의 두 번째 차원이 y의 첫 번째 차원과 같아야 한다.\n",
    "    \n",
    "    z = np.zeros((x.shape[0], y.shape[1])) # 0이 채워진 특정 크기의 벡터를 만든다.\n",
    "    for i in range(x.shape[0]): # x의 행을 반복\n",
    "        for j in range(y.shape[1]): # y의 열을 반복\n",
    "            row_x = x[i,:]\n",
    "            column_y = y[:,j]\n",
    "            z[i,j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tensorflowkorea.files.wordpress.com/2018/12/075.jpg\">  \n",
    "- 그림 : 행렬 점곱 다이어그램  \n",
    "- x의 행 벡터와 y의 열 벡터가 같은 크기여야 하므로 자동으로 x의 너비는 y의 높이와 동일해야 한다.  \n",
    "\n",
    "\n",
    "- 더 일반적으로는 앞서 설명한 2D의 경우처럼 크기를 맞추는 동일한 규칙을 따르면 다음과 같이 고차원 텐서 간의 점곱을 할 수 있다.  \n",
    "(a, b, c, d) . (d,) -> (a, b, c)   \n",
    "(a, b, c, d) . (d, e) -> (a, b, c, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 텐서 크기 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서 크기 변환(tensor reshaping)\n",
    "- 텐서의 크기를 변환한다는 것은 특정 크기에 맞게 열과 행을 재배열한다는 뜻이다.\n",
    "- 크기가 벼환된 텐서는 원래 텐서와 원소 개수가 동일하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0.,1.],\n",
    "              [2.,3.],\n",
    "              [4., 5.]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6,1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 5.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((2,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자주 사용하는 특별한 크기 변환은 전치(tranposition)이다.  \n",
    "- 행렬의 전치는 행과 열을 바꾸는 것  \n",
    "=> x[i,:]이 x[:,i]이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((300,20)) # 모두 0으로 채워진 (300,20) 크기의 행렬을 만든다.\n",
    "x = np.transpose(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 텐서 연산의 기하학적 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서 연산이 조작하는 텐서의 내용은 어떤 기하학적 공간에 있는 좌표 포인트로 해석될 수 있기 때문에 모든 텐서 연산은 기하학적 해석이 가능하다.  \n",
    "- 일반적으로 아핀 변환, 회전, 스케일링 등처럼 기본적인 기하학적 연산은 텐서 연산으로 표현될 수 있다.  \n",
    "(여기서 아핀 변환이란 점, 직선, 평면을 보존하는 아핀 공간으로의 변환을 의미한다. 이 변환은 거리의 비율과 직선의 평행을 유지하는 이동, 스케일링, 회전 등이 포함된다.)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 딥러닝의 기하학적 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신경망은 전체적으로 텐서 연산의 연결로 구성된 것이고, 모든 텐서 연산은 입력 데이터의 기하학적 변환임을 배웟다. 단순한 단계들이 길게 이어져 구현된 신경망을 고차원 공간에서 매우 복잡한 기하학적 변환을 하는 것으로 해석할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
