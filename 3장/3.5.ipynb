{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 뉴스 기사 분류 : 다중 분류 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다중 분류 : 클래스가 많은 경우  \n",
    "  - 단일 레이블 다중 분류 : 각 데이터 포인트가 정확히 하나의 범주로 분류  \n",
    "  - 다중 레이블 다중 분류 : 각 데이터 포인트가 여러 개의 범주에 속할 경우  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 로이터 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 로이터 데이터셋은 1986년에 로이터에서 공개한 <u>짧은 뉴스 기사와 토픽의 집합</u>이다. 이 데이터셋은 텍스트 분류를 위해 널리 사용되는 간단한 데이터셋이다. 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있다. \n",
    "- 케라스에 포함되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\keras\\datasets\\reuters.py:85: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\keras\\datasets\\reuters.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# 로이터 데이터셋 로드\n",
    "from keras.datasets import reuters\n",
    "\n",
    "# 데이터에서 가장 자주 등장하는 단어 1만 개로 제한\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10] # 정수 리스트(단어 인덱스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 2s 3us/step\n"
     ]
    }
   ],
   "source": [
    "# 로이터 데이터셋을 텍스트로 디코딩하기\n",
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]]) # 0,1,2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺀다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수이다.\n",
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 -> 벡터 변환\n",
    "# 데이터 인코딩\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences),dimension))\n",
    "    for i,sequence in enumerate(sequences):\n",
    "        results[i,sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data) # 훈련 데이터 -> 벡터 변환\n",
    "x_test = vectorize_sequences(test_data) # 테스트 데이터 -> 벡터 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블을 벡터로 바꾸는 방법은 2가지가 있다.  \n",
    "1. 레이블의 리스트를 정수 텐서로 변환  \n",
    "2. **원-핫 인코딩 사용**  \n",
    "   - 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩이라고도 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i,label in enumerate(labels):\n",
    "        results[i,label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels) # 훈련 레이블 벡터 변환\n",
    "one_hot_test_labels = to_one_hot(test_labels) # 테스트 레이블 벡터 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_data와 test_data는 파이썬 리스트의 넘파이 배열이기 때문에 to_categorical() 함수를 사용하지 못한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n",
      "2246\n",
      "8982\n",
      "2246\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(one_hot_train_labels))\n",
    "print(len(one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x_train과 x_test의 크기는 각각 (8982, 10000), (2246, 10000)이 되고 one_hot_train_labels와 one_hot_test_labels의 크기는 각각 (8982, 46), (2246, 46)이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내장 함수\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 문제와 비슷해 보이지만 달라진 점은 출력 클래스의 개수가 2에서 46개로 늘어났다는 점이다. 즉, 출력 공간의 차원이 훨씬 커졌다.\n",
    "\n",
    "\n",
    "이전에 사용했던 것처럼 Dense 층을 쌓으면 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있다. 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그 다음 층에서 이를 복원할 방법이 없다. 각 층이 잠재적으로 정보의 병목이 될 수 있다. 이전 예제에서 16차원을 가진 중간층을 사용했찌만 16차원 공간은 46개의 클래스를 구분하기엔 너무 제약이 많을 것 같다. 따라서 좀 더 규모가 큰 층을 사용하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential() # Sequential 모델은 순차적으로 레이어 층을 더해주기 때문에 순차모델이라 불리고 만들기도 쉽다.\n",
    "                            # 출처: https://saengjja.tistory.com/355 [생짜]\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 구조에서 주목해야 할 점이 두가지가 있다.\n",
    "\n",
    "\n",
    "- 마지막 Dense 층의 크기가 46이다. <u>각 입력 샘플에 대해서 46차원의 벡터를 출력한다</u>는 뜻이다. 이 벡터의 각 원소(각 차원)는 각기 다른 출력 클래스가 인코딩된 것이다.  \n",
    "- 마지막 층에 softmax 활성화 함수가 사용되었다. MNIST 예제에서 이런 방식을 보았다. <u>각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력한다. 즉, 46차원의 출력 벡터를 만들며 output[i]는 어떤 샘플이 클래스 i에 속할 확률이다.</u> 46개의 값을 모두 더하면 1이 된다.\n",
    "\n",
    "\n",
    "이런 문제에 사용할 최선의 손실 함수는 **categorical_crossentropy**이다. 이 함수는 <u>두 확률 분포 사이의 거리를 측정</u>한다. 여기에서는 <u>네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리</u>이다. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 훈련 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 세트 준비\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 4s 517us/step - loss: 2.6966 - accuracy: 0.5016 - val_loss: 1.8059 - val_accuracy: 0.6200\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 2s 294us/step - loss: 1.4591 - accuracy: 0.6924 - val_loss: 1.3266 - val_accuracy: 0.7120\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 3s 344us/step - loss: 1.0639 - accuracy: 0.7767 - val_loss: 1.1321 - val_accuracy: 0.7650\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 3s 334us/step - loss: 0.8334 - accuracy: 0.8326 - val_loss: 1.0452 - val_accuracy: 0.7810\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 2s 312us/step - loss: 0.6616 - accuracy: 0.8631 - val_loss: 0.9695 - val_accuracy: 0.7940\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 2s 311us/step - loss: 0.5272 - accuracy: 0.8910 - val_loss: 0.9229 - val_accuracy: 0.8190\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 3s 350us/step - loss: 0.4259 - accuracy: 0.9114 - val_loss: 0.8950 - val_accuracy: 0.8200\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 3s 366us/step - loss: 0.3430 - accuracy: 0.9286 - val_loss: 0.8848 - val_accuracy: 0.8220\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 3s 314us/step - loss: 0.2892 - accuracy: 0.9384 - val_loss: 0.9110 - val_accuracy: 0.8120\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 3s 357us/step - loss: 0.2375 - accuracy: 0.9465 - val_loss: 0.8972 - val_accuracy: 0.8250\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 3s 323us/step - loss: 0.2060 - accuracy: 0.9493 - val_loss: 0.9059 - val_accuracy: 0.8270\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 3s 366us/step - loss: 0.1871 - accuracy: 0.9495 - val_loss: 0.9997 - val_accuracy: 0.8020\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 3s 316us/step - loss: 0.1635 - accuracy: 0.9540 - val_loss: 0.9527 - val_accuracy: 0.8170\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 2s 293us/step - loss: 0.1512 - accuracy: 0.9549 - val_loss: 0.9706 - val_accuracy: 0.8170\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 3s 349us/step - loss: 0.1426 - accuracy: 0.9545 - val_loss: 1.0745 - val_accuracy: 0.8070\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 2s 301us/step - loss: 0.1346 - accuracy: 0.9562 - val_loss: 1.0234 - val_accuracy: 0.8080\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 3s 372us/step - loss: 0.1268 - accuracy: 0.9574 - val_loss: 1.0682 - val_accuracy: 0.7960\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 3s 326us/step - loss: 0.1178 - accuracy: 0.9587 - val_loss: 1.0504 - val_accuracy: 0.8050\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 2s 307us/step - loss: 0.1186 - accuracy: 0.9569 - val_loss: 1.0591 - val_accuracy: 0.8080\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 2s 295us/step - loss: 0.1134 - accuracy: 0.9569 - val_loss: 1.1075 - val_accuracy: 0.8090\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련과 검증 손실 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련과 검증 정확도 그리기\n",
    "plt.clf() # 그래프 초기화\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 모델은 아홉 번째 에포크 이후에 과대적합이 시작된다. 아홉 번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠다.\n",
    "- 모델이 훈련 세트에서는 좋은 성능을 내지만 검증 세트에서는 낮은 성능을 내는 경우 **과대적합**이라고 한다. 예를 들어 모델이 훈련 세트에서는 좋은 성능을 내지만 검증 세트에서는 낮은 성능을 내는 경우가 있다.  \n",
    "(출처: https://asthtls.tistory.com/1021 [포장빵의 IT])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s 406us/step - loss: 2.6742 - accuracy: 0.4615 - val_loss: 1.7693 - val_accuracy: 0.6270\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s 308us/step - loss: 1.4387 - accuracy: 0.6966 - val_loss: 1.3310 - val_accuracy: 0.6980\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s 278us/step - loss: 1.0629 - accuracy: 0.7737 - val_loss: 1.1591 - val_accuracy: 0.7620\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s 294us/step - loss: 0.8307 - accuracy: 0.8252 - val_loss: 1.0306 - val_accuracy: 0.7900\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s 306us/step - loss: 0.6565 - accuracy: 0.8680 - val_loss: 0.9625 - val_accuracy: 0.8040\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 3s 327us/step - loss: 0.5228 - accuracy: 0.8961 - val_loss: 0.9116 - val_accuracy: 0.8120\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 3s 334us/step - loss: 0.4221 - accuracy: 0.9142 - val_loss: 0.8827 - val_accuracy: 0.8100\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s 301us/step - loss: 0.3360 - accuracy: 0.9290 - val_loss: 0.9128 - val_accuracy: 0.8150\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 3s 333us/step - loss: 0.2822 - accuracy: 0.9374 - val_loss: 0.9192 - val_accuracy: 0.8110\n",
      "2246/2246 [==============================] - 1s 442us/step\n"
     ]
    }
   ],
   "source": [
    "# 모델을 처음부터 다시 훈련하기\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=9,\n",
    "         batch_size=512,\n",
    "         validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0067999847001088, 0.7862867116928101]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results # 78%의 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1834372217275156"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy) # list 항목 섞기\n",
    "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "float(np.sum(hits_array)) / len(test_labels) # 무작위로 분류하면 18% 정도의 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.5 새로운 데이터에 대해 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 인스턴스의 predict 메서드는 46개의 토픽에 대한 확률 분포를 반환한다. 테스트 데이터 전체에 대한 토픽을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape # predictions의 각 항목은 46인 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0]) # 벡터의 원소합은 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0]) # 가장 큰 값이 예측 클래스가 된다. 즉, 가장 확률 높은 클래스를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.6 레이블과 손실을 다루는 다른 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블을 인코딩(레이블->벡터)하는 다르방법은 정수 텐서로 변환하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array() 함수는 np.asarray() 함수와 동일하지만 입력된 넘파이 배열의 복사본을 만들어 반환한다.\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정수 레이블을 사용할 때는 sparse_categorical_crossentropy를 사용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.7 충분히 큰 중간층을 두어야 하는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 된다. 46차원보다 훨씬 작은 중간층을 두면 정보의 병목이 발생한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정보의 병목이 있는 모델\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 6s 778us/step - loss: 3.6212 - accuracy: 0.1091 - val_loss: 3.3666 - val_accuracy: 0.1170\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 3s 339us/step - loss: 2.9945 - accuracy: 0.2558 - val_loss: 2.6607 - val_accuracy: 0.3070\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 4s 477us/step - loss: 2.2432 - accuracy: 0.3096 - val_loss: 1.9875 - val_accuracy: 0.5030\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 3s 419us/step - loss: 1.5764 - accuracy: 0.6170 - val_loss: 1.5442 - val_accuracy: 0.6140\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 3s 360us/step - loss: 1.2586 - accuracy: 0.6676 - val_loss: 1.4236 - val_accuracy: 0.6580\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 4s 457us/step - loss: 1.0979 - accuracy: 0.7255 - val_loss: 1.3858 - val_accuracy: 0.6760\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 3s 377us/step - loss: 0.9857 - accuracy: 0.7522 - val_loss: 1.3470 - val_accuracy: 0.6950\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 3s 357us/step - loss: 0.8960 - accuracy: 0.7705 - val_loss: 1.3577 - val_accuracy: 0.6990\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 4s 506us/step - loss: 0.8237 - accuracy: 0.7860 - val_loss: 1.3883 - val_accuracy: 0.6970\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 3s 349us/step - loss: 0.7582 - accuracy: 0.8001 - val_loss: 1.3769 - val_accuracy: 0.7110\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 3s 401us/step - loss: 0.7066 - accuracy: 0.8137 - val_loss: 1.4359 - val_accuracy: 0.7010\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 3s 424us/step - loss: 0.6627 - accuracy: 0.8241 - val_loss: 1.4154 - val_accuracy: 0.7070\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 3s 385us/step - loss: 0.6181 - accuracy: 0.8340 - val_loss: 1.5008 - val_accuracy: 0.6990\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 3s 425us/step - loss: 0.5846 - accuracy: 0.8414 - val_loss: 1.5013 - val_accuracy: 0.7040\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 3s 415us/step - loss: 0.5489 - accuracy: 0.8500 - val_loss: 1.6014 - val_accuracy: 0.7040\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 3s 412us/step - loss: 0.5183 - accuracy: 0.8574 - val_loss: 1.5905 - val_accuracy: 0.7020\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 4s 469us/step - loss: 0.4922 - accuracy: 0.8678 - val_loss: 1.6298 - val_accuracy: 0.7000\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 3s 379us/step - loss: 0.4667 - accuracy: 0.8752 - val_loss: 1.7208 - val_accuracy: 0.6990\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 3s 391us/step - loss: 0.4445 - accuracy: 0.8795 - val_loss: 1.7195 - val_accuracy: 0.7000\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 3s 432us/step - loss: 0.4276 - accuracy: 0.8859 - val_loss: 1.8514 - val_accuracy: 0.7010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26e106b45f8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=20,\n",
    "         batch_size=128,\n",
    "         validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 정확도의 최고 값은 71%로 8% 정도로 감소되었다. 이런 손실의 원인 대부분은 많은 정보를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 1s 480us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.4397770307579956, 0.6736420392990112]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,one_hot_test_labels) # 67%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.8 추가 실험\n",
    "- 더 크거나 작은 층을 사용해 보기. ex. 32개의 유닛, 128개의 유닛 등  \n",
    "- 여기에서 2개의 은닉 층을 사용했으니 1개나 3개의 은닉 층을 사용해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.9 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 Dense 층의 크기는 N이어야 한다.  \n",
    "2. <u>단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해</u> **softmax 활성화 함수**를 사용해야 한다.  \n",
    "3. 이런 문제에는 항상 **범주형 크로스엔트로피**를 사용해야 한다. 이 함수는 <u>모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화</u>한다.  \n",
    "4. 다중 분류에서 레이블을 다루는 두 가지 방법이 있다.\n",
    "    - 레이블을 **범주형 인코딩**(또는 원-핫 인코딩)으로 인코딩하고 categorical_crossentropy 손실 함수를 사용한다.  \n",
    "    - 레이블을 **정수로 인코딩**하고 sparse_categorical_crossentropy 손실 함수를 사용한다.  \n",
    "5. 많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 주의해야 한다.     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
